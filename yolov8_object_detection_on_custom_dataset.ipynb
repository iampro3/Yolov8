{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iampro3/Yolov8/blob/main/yolov8_object_detection_on_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "ac046747-9f8a-43be-ce55-17b150563b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "ba994a42-d8f4-40bc-81ff-fb8002a8c784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 26.3/166.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVvaIYEEPOty"
      },
      "outputs": [],
      "source": [
        "# Git clone method (for development)\n",
        "\n",
        "# %cd {HOME}\n",
        "# !git clone github.com/ultralytics/ultralytics\n",
        "# %cd {HOME}/ultralytics\n",
        "# !pip install -qe ultralytics\n",
        "\n",
        "# from IPython import display\n",
        "# display.clear_output()\n",
        "\n",
        "# import ultralytics\n",
        "# ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33S7zlkQku0"
      },
      "source": [
        "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://v8docs.ultralytics.com/cli/).\n",
        "\n",
        "```\n",
        "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
        "          classify       predict        yolov8n-cls.yaml  args...\n",
        "          segment        val            yolov8n-seg.yaml  args...\n",
        "                         export         yolov8n.pt        format=onnx  args...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### üíª CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaE1kLS8R4CV"
      },
      "source": [
        "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbMt_M6PiXb",
        "outputId": "221dc9c6-60cd-48a6-f218-07c8b3d3b23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 74.6MB/s]\n",
            "\n",
            "2023-12-21 14:41:04.568483: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-21 14:41:04.568534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-21 14:41:04.570503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-21 14:41:06.727307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "Downloading https://media.roboflow.com/notebooks/examples/dog.jpeg to dog.jpeg...\n",
            "100% 104k/104k [00:00<00:00, 49.0MB/s]\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/dog.jpeg: 640x384 1 person, 1 car, 1 dog, 104.1ms\n",
            "Speed: 0.7ms pre-process, 104.1ms inference, 749.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jze57H3ayc6b",
        "outputId": "d7447b6b-1e65-4278-ae98-8ea368454df8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            " cameracalib_231020.ipynb\t       pytorch02_231024.ipynb\n",
            " catanddog\t\t\t       Pytorch_·ÑÄ·Ö¢·Ü®·Ñé·Ö¶·ÑÜ·Öµ·Ñâ·Ö¶·ÑÄ·Ö•·Ü∑·Ñé·ÖÆ·ÜØ.ipynb\n",
            " CNN_Lanedetection_0818.ipynb\t       semanticseg_0819.ipynb\n",
            "'Colab Notebooks'\t\t       smoke\n",
            " crawling-bs4selen\t\t      'Stable diffusion'\n",
            " cv2\t\t\t\t       study\n",
            " DAE\t\t\t\t      'Swin Transformers_0821.ipynb'\n",
            " data\t\t\t\t       tfdeepln_0524\n",
            "'deep learning ·Ñã·Öµ·Ü´·ÑÄ·Ö©·Üº·Ñâ·Öµ·Ü´·ÑÄ·Öß·Üº·ÑÜ·Ö°·Üº'\t       torchvision\n",
            " Detectron2_0819.ipynb\t\t       Untitled0.ipynb\n",
            " EXperience\t\t\t       Untitled1.ipynb\n",
            "'Face detection_0819.ipynb'\t       Untitled2.ipynb\n",
            " freedomtech.zip\t\t       Untitled3.ipynb\n",
            " hardhat\t\t\t       Untitled4.ipynb\n",
            " health_0525\t\t\t       Untitled5.ipynb\n",
            "' Image classification_0821.ipynb'     Untitled6.ipynb\n",
            " indi_tensor\t\t\t       Untitled7.ipynb\n",
            " inference_image.ipynb\t\t       Untitled8.ipynb\n",
            " LaneDetection_0821.ipynb\t       yolov7.gdoc\n",
            " Lidar_3D_ObjectDetection_0822.ipynb   yolov7.pdf\n",
            " mmlab\t\t\t\t       yolov8_object_detection_on_custom_dataset.ipynb\n",
            " Objectdection_pytorch.ipynb\t       Yolov8_object-tracking\n",
            " Objectdetection_YOLO_0814.ipynb       ·Ñâ·Ö°·Ü´·ÑÉ·Ö¢·Ñê·Ö≥·Ü®\n",
            " opencv_231018.ipynb\t\t      '·Ñã·Öß·Ü´·ÑÄ·Ö°·Ü´ ·ÑÄ·Ö°·ÑÄ·Ö®·Ñá·ÖÆ.gsheet'\n",
            " PointCloud_0821.ipynb\t\t      '·Ñã·ÖØ·ÜØ·ÑÄ·Ö°·Ü´ ·ÑÄ·Ö°·ÑÄ·Ö®·Ñá·ÖÆ.gsheet'\n",
            " pothole\t\t\t      '·Ñå·Ö¶·ÑÜ·Ö©·Ü® ·Ñã·Ö•·Üπ·ÑÇ·Ö≥·Ü´ ·Ñë·Ö≥·ÑÖ·Ö¶·Ñå·Ö¶·Ü´·Ñê·Ö¶·Ñã·Öµ·Ñâ·Öß·Ü´.gslides'\n",
            " ppt\t\t\t\t       ·Ñè·Ö©·ÑÉ·Ö≥·Ñã·Ö•·Üπ·ÑÇ·Ö≥·Ü´·Ñë·Ö≥·ÑÖ·Ö©·ÑÄ·Ö≥·ÑÖ·Ö¢·ÑÜ·Öµ·Üº\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "65718c61-3a3f-4b50-efde-4ee095e4a774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "Archive:  /content/gdrive/MyDrive/freedomtech.zip\n",
            "   creating: images/\n",
            "   creating: images/trainging/\n",
            "  inflating: images/trainging/classes.txt  \n",
            "  inflating: images/trainging/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.jpg  \n",
            " extracting: images/trainging/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.txt  \n",
            "  inflating: images/trainging/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.jpg  \n",
            " extracting: images/trainging/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.txt  \n",
            "  inflating: images/trainging/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.jpg  \n",
            " extracting: images/trainging/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.txt  \n",
            "  inflating: images/trainging/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.jpg  \n",
            " extracting: images/trainging/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.txt  \n",
            "  inflating: images/trainging/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.jpg  \n",
            "  inflating: images/trainging/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.txt  \n",
            "  inflating: images/trainging/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.jpg  \n",
            "  inflating: images/trainging/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.txt  \n",
            "  inflating: images/trainging/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.jpg  \n",
            " extracting: images/trainging/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.txt  \n",
            "  inflating: images/trainging/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.jpg  \n",
            "  inflating: images/trainging/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.txt  \n",
            "  inflating: images/trainging/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.jpg  \n",
            " extracting: images/trainging/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.txt  \n",
            "  inflating: images/trainging/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.jpg  \n",
            "  inflating: images/trainging/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.txt  \n",
            "  inflating: images/trainging/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.jpg  \n",
            "  inflating: images/trainging/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.txt  \n",
            "  inflating: images/trainging/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.jpg  \n",
            "  inflating: images/trainging/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.txt  \n",
            "  inflating: images/trainging/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.jpg  \n",
            " extracting: images/trainging/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.txt  \n",
            "  inflating: images/trainging/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.jpg  \n",
            "  inflating: images/trainging/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.txt  \n",
            "  inflating: images/trainging/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.jpg  \n",
            "  inflating: images/trainging/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.txt  \n",
            "  inflating: images/trainging/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.jpg  \n",
            "  inflating: images/trainging/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.txt  \n",
            "  inflating: images/trainging/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.jpg  \n",
            " extracting: images/trainging/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.txt  \n",
            "  inflating: images/trainging/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.jpg  \n",
            " extracting: images/trainging/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.txt  \n",
            "  inflating: images/trainging/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.jpg  \n",
            " extracting: images/trainging/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.txt  \n",
            "  inflating: images/trainging/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.jpg  \n",
            " extracting: images/trainging/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.txt  \n",
            "  inflating: images/trainging/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.jpg  \n",
            " extracting: images/trainging/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.txt  \n",
            "  inflating: images/trainging/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.jpg  \n",
            " extracting: images/trainging/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.txt  \n",
            "  inflating: images/trainging/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.jpg  \n",
            " extracting: images/trainging/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.txt  \n",
            "  inflating: images/trainging/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.jpg  \n",
            " extracting: images/trainging/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.txt  \n",
            "  inflating: images/trainging/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.jpg  \n",
            " extracting: images/trainging/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.txt  \n",
            "  inflating: images/trainging/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.jpg  \n",
            " extracting: images/trainging/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.txt  \n",
            "  inflating: images/trainging/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.jpg  \n",
            " extracting: images/trainging/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.txt  \n",
            "  inflating: images/trainging/person_149_jpg.rf.88955d0abb653e767920572661b3c985.jpg  \n",
            " extracting: images/trainging/person_149_jpg.rf.88955d0abb653e767920572661b3c985.txt  \n",
            "  inflating: images/trainging/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.jpg  \n",
            " extracting: images/trainging/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.txt  \n",
            "  inflating: images/trainging/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.jpg  \n",
            " extracting: images/trainging/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.txt  \n",
            "  inflating: images/trainging/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.jpg  \n",
            " extracting: images/trainging/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.txt  \n",
            "  inflating: images/trainging/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.jpg  \n",
            " extracting: images/trainging/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.txt  \n",
            "  inflating: images/trainging/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.jpg  \n",
            "  inflating: images/trainging/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.txt  \n",
            "  inflating: images/trainging/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.jpg  \n",
            "  inflating: images/trainging/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.txt  \n",
            "  inflating: images/trainging/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.jpg  \n",
            "  inflating: images/trainging/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.txt  \n",
            "  inflating: images/trainging/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.jpg  \n",
            "  inflating: images/trainging/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.txt  \n",
            "  inflating: images/trainging/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.jpg  \n",
            "  inflating: images/trainging/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.txt  \n",
            "  inflating: images/trainging/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.jpg  \n",
            "  inflating: images/trainging/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.txt  \n",
            "  inflating: images/trainging/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.jpg  \n",
            "  inflating: images/trainging/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.txt  \n",
            "  inflating: images/trainging/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.jpg  \n",
            "  inflating: images/trainging/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.txt  \n",
            "  inflating: images/trainging/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.jpg  \n",
            "  inflating: images/trainging/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.txt  \n",
            "  inflating: images/trainging/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.jpg  \n",
            " extracting: images/trainging/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.txt  \n",
            "  inflating: images/trainging/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.jpg  \n",
            "  inflating: images/trainging/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.txt  \n",
            "  inflating: images/trainging/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.jpg  \n",
            "  inflating: images/trainging/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.txt  \n",
            "  inflating: images/trainging/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.jpg  \n",
            "  inflating: images/trainging/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.txt  \n",
            "  inflating: images/trainging/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.jpg  \n",
            "  inflating: images/trainging/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.txt  \n",
            "  inflating: images/trainging/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.jpg  \n",
            "  inflating: images/trainging/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.txt  \n",
            "  inflating: images/trainging/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.jpg  \n",
            "  inflating: images/trainging/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.txt  \n",
            "  inflating: images/trainging/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.jpg  \n",
            "  inflating: images/trainging/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.txt  \n",
            "  inflating: images/trainging/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.jpg  \n",
            " extracting: images/trainging/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.txt  \n",
            "  inflating: images/trainging/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.jpg  \n",
            "  inflating: images/trainging/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.txt  \n",
            "  inflating: images/trainging/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.jpg  \n",
            "  inflating: images/trainging/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.txt  \n",
            "  inflating: images/trainging/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.jpg  \n",
            "  inflating: images/trainging/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.txt  \n",
            "  inflating: images/trainging/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.jpg  \n",
            "  inflating: images/trainging/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.txt  \n",
            "  inflating: images/trainging/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.jpg  \n",
            "  inflating: images/trainging/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.txt  \n",
            "  inflating: images/trainging/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.jpg  \n",
            "  inflating: images/trainging/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.txt  \n",
            "  inflating: images/trainging/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.jpg  \n",
            " extracting: images/trainging/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.txt  \n",
            "  inflating: images/trainging/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.jpg  \n",
            "  inflating: images/trainging/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.txt  \n",
            "  inflating: images/trainging/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.jpg  \n",
            "  inflating: images/trainging/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.txt  \n",
            "  inflating: images/trainging/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.jpg  \n",
            "  inflating: images/trainging/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.txt  \n",
            "  inflating: images/trainging/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.jpg  \n",
            "  inflating: images/trainging/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.txt  \n",
            "  inflating: images/trainging/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.jpg  \n",
            "  inflating: images/trainging/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.txt  \n",
            "  inflating: images/trainging/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.jpg  \n",
            "  inflating: images/trainging/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.txt  \n",
            "  inflating: images/trainging/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.jpg  \n",
            "  inflating: images/trainging/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.txt  \n",
            "  inflating: images/trainging/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.jpg  \n",
            "  inflating: images/trainging/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.txt  \n",
            "  inflating: images/trainging/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.jpg  \n",
            "  inflating: images/trainging/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.txt  \n",
            "  inflating: images/trainging/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.jpg  \n",
            "  inflating: images/trainging/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.txt  \n",
            "  inflating: images/trainging/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.jpg  \n",
            "  inflating: images/trainging/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.txt  \n",
            "  inflating: images/trainging/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.jpg  \n",
            "  inflating: images/trainging/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.txt  \n",
            "  inflating: images/trainging/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.jpg  \n",
            "  inflating: images/trainging/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.txt  \n",
            "  inflating: images/trainging/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.jpg  \n",
            "  inflating: images/trainging/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.txt  \n",
            "  inflating: images/trainging/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.jpg  \n",
            "  inflating: images/trainging/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.txt  \n",
            "  inflating: images/trainging/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.jpg  \n",
            "  inflating: images/trainging/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.txt  \n",
            "   creating: images/validation/\n",
            "  inflating: images/validation/classes.txt  \n",
            "  inflating: images/validation/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.jpg  \n",
            " extracting: images/validation/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.txt  \n",
            "  inflating: images/validation/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.jpg  \n",
            " extracting: images/validation/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.txt  \n",
            "  inflating: images/validation/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.jpg  \n",
            " extracting: images/validation/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.txt  \n",
            "  inflating: images/validation/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.jpg  \n",
            " extracting: images/validation/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.txt  \n",
            "  inflating: images/validation/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.jpg  \n",
            "  inflating: images/validation/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.txt  \n",
            "  inflating: images/validation/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.jpg  \n",
            "  inflating: images/validation/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.txt  \n",
            "  inflating: images/validation/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.jpg  \n",
            " extracting: images/validation/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.txt  \n",
            "  inflating: images/validation/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.jpg  \n",
            "  inflating: images/validation/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.txt  \n",
            "  inflating: images/validation/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.jpg  \n",
            " extracting: images/validation/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.txt  \n",
            "  inflating: images/validation/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.jpg  \n",
            "  inflating: images/validation/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.txt  \n",
            "  inflating: images/validation/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.jpg  \n",
            "  inflating: images/validation/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.txt  \n",
            "  inflating: images/validation/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.jpg  \n",
            "  inflating: images/validation/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.txt  \n",
            "  inflating: images/validation/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.jpg  \n",
            " extracting: images/validation/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.txt  \n",
            "  inflating: images/validation/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.jpg  \n",
            "  inflating: images/validation/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.txt  \n",
            "  inflating: images/validation/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.jpg  \n",
            "  inflating: images/validation/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.txt  \n",
            "  inflating: images/validation/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.jpg  \n",
            "  inflating: images/validation/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.txt  \n",
            "  inflating: images/validation/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.jpg  \n",
            " extracting: images/validation/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.txt  \n",
            "  inflating: images/validation/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.jpg  \n",
            " extracting: images/validation/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.txt  \n",
            "  inflating: images/validation/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.jpg  \n",
            " extracting: images/validation/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.txt  \n",
            "  inflating: images/validation/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.jpg  \n",
            " extracting: images/validation/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.txt  \n",
            "  inflating: images/validation/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.jpg  \n",
            " extracting: images/validation/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.txt  \n",
            "  inflating: images/validation/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.jpg  \n",
            " extracting: images/validation/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.txt  \n",
            "  inflating: images/validation/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.jpg  \n",
            " extracting: images/validation/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.txt  \n",
            "  inflating: images/validation/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.jpg  \n",
            " extracting: images/validation/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.txt  \n",
            "  inflating: images/validation/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.jpg  \n",
            " extracting: images/validation/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.txt  \n",
            "  inflating: images/validation/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.jpg  \n",
            " extracting: images/validation/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.txt  \n",
            "  inflating: images/validation/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.jpg  \n",
            " extracting: images/validation/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.txt  \n",
            "  inflating: images/validation/person_149_jpg.rf.88955d0abb653e767920572661b3c985.jpg  \n",
            " extracting: images/validation/person_149_jpg.rf.88955d0abb653e767920572661b3c985.txt  \n",
            "  inflating: images/validation/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.jpg  \n",
            " extracting: images/validation/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.txt  \n",
            "  inflating: images/validation/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.jpg  \n",
            " extracting: images/validation/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.txt  \n",
            "  inflating: images/validation/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.jpg  \n",
            " extracting: images/validation/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.txt  \n",
            "  inflating: images/validation/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.jpg  \n",
            " extracting: images/validation/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.txt  \n",
            "  inflating: images/validation/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.jpg  \n",
            "  inflating: images/validation/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.txt  \n",
            "  inflating: images/validation/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.jpg  \n",
            "  inflating: images/validation/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.txt  \n",
            "  inflating: images/validation/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.jpg  \n",
            "  inflating: images/validation/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.txt  \n",
            "  inflating: images/validation/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.jpg  \n",
            "  inflating: images/validation/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.txt  \n",
            "  inflating: images/validation/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.jpg  \n",
            "  inflating: images/validation/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.txt  \n",
            "  inflating: images/validation/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.jpg  \n",
            "  inflating: images/validation/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.txt  \n",
            "  inflating: images/validation/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.jpg  \n",
            "  inflating: images/validation/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.txt  \n",
            "  inflating: images/validation/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.jpg  \n",
            "  inflating: images/validation/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.txt  \n",
            "  inflating: images/validation/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.jpg  \n",
            "  inflating: images/validation/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.txt  \n",
            "  inflating: images/validation/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.jpg  \n",
            " extracting: images/validation/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.txt  \n",
            "  inflating: images/validation/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.jpg  \n",
            "  inflating: images/validation/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.txt  \n",
            "  inflating: images/validation/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.jpg  \n",
            "  inflating: images/validation/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.txt  \n",
            "  inflating: images/validation/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.jpg  \n",
            "  inflating: images/validation/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.txt  \n",
            "  inflating: images/validation/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.jpg  \n",
            "  inflating: images/validation/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.txt  \n",
            "  inflating: images/validation/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.jpg  \n",
            "  inflating: images/validation/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.txt  \n",
            "  inflating: images/validation/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.jpg  \n",
            "  inflating: images/validation/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.txt  \n",
            "  inflating: images/validation/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.jpg  \n",
            "  inflating: images/validation/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.txt  \n",
            "  inflating: images/validation/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.jpg  \n",
            " extracting: images/validation/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.txt  \n",
            "  inflating: images/validation/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.jpg  \n",
            "  inflating: images/validation/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.txt  \n",
            "  inflating: images/validation/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.jpg  \n",
            "  inflating: images/validation/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.txt  \n",
            "  inflating: images/validation/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.jpg  \n",
            "  inflating: images/validation/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.txt  \n",
            "  inflating: images/validation/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.jpg  \n",
            "  inflating: images/validation/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.txt  \n",
            "  inflating: images/validation/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.jpg  \n",
            "  inflating: images/validation/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.txt  \n",
            "  inflating: images/validation/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.jpg  \n",
            "  inflating: images/validation/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.txt  \n",
            "  inflating: images/validation/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.jpg  \n",
            " extracting: images/validation/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.txt  \n",
            "  inflating: images/validation/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.jpg  \n",
            "  inflating: images/validation/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.txt  \n",
            "  inflating: images/validation/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.jpg  \n",
            "  inflating: images/validation/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.txt  \n",
            "  inflating: images/validation/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.jpg  \n",
            "  inflating: images/validation/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.txt  \n",
            "  inflating: images/validation/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.jpg  \n",
            "  inflating: images/validation/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.txt  \n",
            "  inflating: images/validation/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.jpg  \n",
            "  inflating: images/validation/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.txt  \n",
            "  inflating: images/validation/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.jpg  \n",
            "  inflating: images/validation/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.txt  \n",
            "  inflating: images/validation/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.jpg  \n",
            "  inflating: images/validation/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.txt  \n",
            "  inflating: images/validation/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.jpg  \n",
            "  inflating: images/validation/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.txt  \n",
            "  inflating: images/validation/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.jpg  \n",
            "  inflating: images/validation/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.txt  \n",
            "  inflating: images/validation/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.jpg  \n",
            "  inflating: images/validation/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.txt  \n",
            "  inflating: images/validation/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.jpg  \n",
            "  inflating: images/validation/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.txt  \n",
            "  inflating: images/validation/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.jpg  \n",
            "  inflating: images/validation/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.txt  \n",
            "  inflating: images/validation/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.jpg  \n",
            "  inflating: images/validation/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.txt  \n",
            "  inflating: images/validation/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.jpg  \n",
            "  inflating: images/validation/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.txt  \n",
            "  inflating: images/validation/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.jpg  \n",
            "  inflating: images/validation/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.txt  \n",
            "  inflating: images/validation/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.jpg  \n",
            "  inflating: images/validation/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.txt  \n",
            "   creating: labels/\n",
            "   creating: labels/trainging/\n",
            "  inflating: labels/trainging/classes.txt  \n",
            "  inflating: labels/trainging/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.jpg  \n",
            " extracting: labels/trainging/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.txt  \n",
            "  inflating: labels/trainging/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.jpg  \n",
            " extracting: labels/trainging/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.txt  \n",
            "  inflating: labels/trainging/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.jpg  \n",
            " extracting: labels/trainging/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.txt  \n",
            "  inflating: labels/trainging/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.jpg  \n",
            " extracting: labels/trainging/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.txt  \n",
            "  inflating: labels/trainging/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.jpg  \n",
            "  inflating: labels/trainging/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.txt  \n",
            "  inflating: labels/trainging/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.jpg  \n",
            "  inflating: labels/trainging/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.txt  \n",
            "  inflating: labels/trainging/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.jpg  \n",
            " extracting: labels/trainging/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.txt  \n",
            "  inflating: labels/trainging/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.jpg  \n",
            "  inflating: labels/trainging/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.txt  \n",
            "  inflating: labels/trainging/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.jpg  \n",
            " extracting: labels/trainging/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.txt  \n",
            "  inflating: labels/trainging/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.jpg  \n",
            "  inflating: labels/trainging/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.txt  \n",
            "  inflating: labels/trainging/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.jpg  \n",
            "  inflating: labels/trainging/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.txt  \n",
            "  inflating: labels/trainging/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.jpg  \n",
            "  inflating: labels/trainging/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.txt  \n",
            "  inflating: labels/trainging/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.jpg  \n",
            " extracting: labels/trainging/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.txt  \n",
            "  inflating: labels/trainging/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.jpg  \n",
            "  inflating: labels/trainging/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.txt  \n",
            "  inflating: labels/trainging/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.jpg  \n",
            "  inflating: labels/trainging/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.txt  \n",
            "  inflating: labels/trainging/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.jpg  \n",
            "  inflating: labels/trainging/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.txt  \n",
            "  inflating: labels/trainging/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.jpg  \n",
            " extracting: labels/trainging/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.txt  \n",
            "  inflating: labels/trainging/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.jpg  \n",
            " extracting: labels/trainging/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.txt  \n",
            "  inflating: labels/trainging/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.jpg  \n",
            " extracting: labels/trainging/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.txt  \n",
            "  inflating: labels/trainging/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.jpg  \n",
            " extracting: labels/trainging/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.txt  \n",
            "  inflating: labels/trainging/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.jpg  \n",
            " extracting: labels/trainging/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.txt  \n",
            "  inflating: labels/trainging/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.jpg  \n",
            " extracting: labels/trainging/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.txt  \n",
            "  inflating: labels/trainging/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.jpg  \n",
            " extracting: labels/trainging/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.txt  \n",
            "  inflating: labels/trainging/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.jpg  \n",
            " extracting: labels/trainging/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.txt  \n",
            "  inflating: labels/trainging/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.jpg  \n",
            " extracting: labels/trainging/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.txt  \n",
            "  inflating: labels/trainging/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.jpg  \n",
            " extracting: labels/trainging/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.txt  \n",
            "  inflating: labels/trainging/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.jpg  \n",
            " extracting: labels/trainging/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.txt  \n",
            "  inflating: labels/trainging/person_149_jpg.rf.88955d0abb653e767920572661b3c985.jpg  \n",
            " extracting: labels/trainging/person_149_jpg.rf.88955d0abb653e767920572661b3c985.txt  \n",
            "  inflating: labels/trainging/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.jpg  \n",
            " extracting: labels/trainging/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.txt  \n",
            "  inflating: labels/trainging/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.jpg  \n",
            " extracting: labels/trainging/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.txt  \n",
            "  inflating: labels/trainging/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.jpg  \n",
            " extracting: labels/trainging/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.txt  \n",
            "  inflating: labels/trainging/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.jpg  \n",
            " extracting: labels/trainging/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.txt  \n",
            "  inflating: labels/trainging/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.jpg  \n",
            "  inflating: labels/trainging/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.txt  \n",
            "  inflating: labels/trainging/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.jpg  \n",
            "  inflating: labels/trainging/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.txt  \n",
            "  inflating: labels/trainging/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.jpg  \n",
            "  inflating: labels/trainging/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.txt  \n",
            "  inflating: labels/trainging/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.jpg  \n",
            "  inflating: labels/trainging/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.txt  \n",
            "  inflating: labels/trainging/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.jpg  \n",
            "  inflating: labels/trainging/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.txt  \n",
            "  inflating: labels/trainging/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.jpg  \n",
            "  inflating: labels/trainging/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.txt  \n",
            "  inflating: labels/trainging/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.jpg  \n",
            "  inflating: labels/trainging/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.txt  \n",
            "  inflating: labels/trainging/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.jpg  \n",
            "  inflating: labels/trainging/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.txt  \n",
            "  inflating: labels/trainging/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.jpg  \n",
            "  inflating: labels/trainging/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.txt  \n",
            "  inflating: labels/trainging/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.jpg  \n",
            " extracting: labels/trainging/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.txt  \n",
            "  inflating: labels/trainging/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.jpg  \n",
            "  inflating: labels/trainging/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.txt  \n",
            "  inflating: labels/trainging/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.jpg  \n",
            "  inflating: labels/trainging/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.txt  \n",
            "  inflating: labels/trainging/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.jpg  \n",
            "  inflating: labels/trainging/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.txt  \n",
            "  inflating: labels/trainging/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.jpg  \n",
            "  inflating: labels/trainging/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.txt  \n",
            "  inflating: labels/trainging/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.jpg  \n",
            "  inflating: labels/trainging/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.txt  \n",
            "  inflating: labels/trainging/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.jpg  \n",
            "  inflating: labels/trainging/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.txt  \n",
            "  inflating: labels/trainging/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.jpg  \n",
            "  inflating: labels/trainging/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.txt  \n",
            "  inflating: labels/trainging/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.jpg  \n",
            " extracting: labels/trainging/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.txt  \n",
            "  inflating: labels/trainging/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.jpg  \n",
            "  inflating: labels/trainging/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.txt  \n",
            "  inflating: labels/trainging/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.jpg  \n",
            "  inflating: labels/trainging/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.txt  \n",
            "  inflating: labels/trainging/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.jpg  \n",
            "  inflating: labels/trainging/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.txt  \n",
            "  inflating: labels/trainging/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.jpg  \n",
            "  inflating: labels/trainging/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.txt  \n",
            "  inflating: labels/trainging/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.jpg  \n",
            "  inflating: labels/trainging/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.txt  \n",
            "  inflating: labels/trainging/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.jpg  \n",
            "  inflating: labels/trainging/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.txt  \n",
            "  inflating: labels/trainging/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.jpg  \n",
            " extracting: labels/trainging/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.txt  \n",
            "  inflating: labels/trainging/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.jpg  \n",
            "  inflating: labels/trainging/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.txt  \n",
            "  inflating: labels/trainging/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.jpg  \n",
            "  inflating: labels/trainging/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.txt  \n",
            "  inflating: labels/trainging/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.jpg  \n",
            "  inflating: labels/trainging/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.txt  \n",
            "  inflating: labels/trainging/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.jpg  \n",
            "  inflating: labels/trainging/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.txt  \n",
            "  inflating: labels/trainging/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.jpg  \n",
            "  inflating: labels/trainging/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.txt  \n",
            "  inflating: labels/trainging/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.jpg  \n",
            "  inflating: labels/trainging/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.txt  \n",
            "  inflating: labels/trainging/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.jpg  \n",
            "  inflating: labels/trainging/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.txt  \n",
            "  inflating: labels/trainging/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.jpg  \n",
            "  inflating: labels/trainging/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.txt  \n",
            "  inflating: labels/trainging/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.jpg  \n",
            "  inflating: labels/trainging/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.txt  \n",
            "  inflating: labels/trainging/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.jpg  \n",
            "  inflating: labels/trainging/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.txt  \n",
            "  inflating: labels/trainging/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.jpg  \n",
            "  inflating: labels/trainging/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.txt  \n",
            "  inflating: labels/trainging/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.jpg  \n",
            "  inflating: labels/trainging/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.txt  \n",
            "  inflating: labels/trainging/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.jpg  \n",
            "  inflating: labels/trainging/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.txt  \n",
            "  inflating: labels/trainging/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.jpg  \n",
            "  inflating: labels/trainging/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.txt  \n",
            "  inflating: labels/trainging/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.jpg  \n",
            "  inflating: labels/trainging/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.txt  \n",
            "  inflating: labels/trainging/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.jpg  \n",
            "  inflating: labels/trainging/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.txt  \n",
            "   creating: labels/validation/\n",
            "  inflating: labels/validation/classes.txt  \n",
            "  inflating: labels/validation/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.jpg  \n",
            " extracting: labels/validation/person_0_jpg.rf.d2e34da5cf249832e1eaf7b562c0ebe6.txt  \n",
            "  inflating: labels/validation/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.jpg  \n",
            " extracting: labels/validation/person_100_jpg.rf.97656b9136a92e5bfed2d4437a5e8c99.txt  \n",
            "  inflating: labels/validation/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.jpg  \n",
            " extracting: labels/validation/person_106_jpg.rf.efe2ef9a2d3c0c944025160565fc601c.txt  \n",
            "  inflating: labels/validation/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.jpg  \n",
            " extracting: labels/validation/person_107_jpg.rf.e82c3ce416c1886576732113f24759cc.txt  \n",
            "  inflating: labels/validation/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.jpg  \n",
            "  inflating: labels/validation/person_111_jpg.rf.bcce7644cbc3eba1d22a71333805dfc6.txt  \n",
            "  inflating: labels/validation/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.jpg  \n",
            "  inflating: labels/validation/person_112_jpg.rf.f9b78f112ffbc144b71ad60911c8e5c0.txt  \n",
            "  inflating: labels/validation/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.jpg  \n",
            " extracting: labels/validation/person_113_jpg.rf.dbd49d0503583194fd0a3979e103aed5.txt  \n",
            "  inflating: labels/validation/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.jpg  \n",
            "  inflating: labels/validation/person_114_jpg.rf.3eca5f8f744fb3f6431f7a6b900d97ea.txt  \n",
            "  inflating: labels/validation/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.jpg  \n",
            " extracting: labels/validation/person_115_jpg.rf.da5db6a25f7f8da2ddc0795640d1452d.txt  \n",
            "  inflating: labels/validation/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.jpg  \n",
            "  inflating: labels/validation/person_117_jpg.rf.cfbeff10994df6b45d7e1d2b844f1b1d.txt  \n",
            "  inflating: labels/validation/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.jpg  \n",
            "  inflating: labels/validation/person_118_jpg.rf.70098f90e4e55463878edd4d1a6b4351.txt  \n",
            "  inflating: labels/validation/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.jpg  \n",
            "  inflating: labels/validation/person_119_jpg.rf.e3fc47bbb66abf53f37df4963d6c94a3.txt  \n",
            "  inflating: labels/validation/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.jpg  \n",
            " extracting: labels/validation/person_11_jpg.rf.3d50d3c37546b2d3cbb5d9fcccabc9b7.txt  \n",
            "  inflating: labels/validation/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.jpg  \n",
            "  inflating: labels/validation/person_120_jpg.rf.1842172a7facb6a712cf8a14fb07b134.txt  \n",
            "  inflating: labels/validation/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.jpg  \n",
            "  inflating: labels/validation/person_121_jpg.rf.d8ac126b1677fa282e4c72c9701ee12f.txt  \n",
            "  inflating: labels/validation/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.jpg  \n",
            "  inflating: labels/validation/person_122_jpg.rf.c2512683c72fce5601543787dc93cd5a.txt  \n",
            "  inflating: labels/validation/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.jpg  \n",
            " extracting: labels/validation/person_126_jpg.rf.ef037928f1218850b4168a7434cdf856.txt  \n",
            "  inflating: labels/validation/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.jpg  \n",
            " extracting: labels/validation/person_129_jpg.rf.8b0d8532e1bbbd5e861f83a6dfb53940.txt  \n",
            "  inflating: labels/validation/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.jpg  \n",
            " extracting: labels/validation/person_134_jpg.rf.eec56c4c9e856abdeb42ef605b00e196.txt  \n",
            "  inflating: labels/validation/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.jpg  \n",
            " extracting: labels/validation/person_137_jpg.rf.976c156a3946e20e4f6344d97fa5eb01.txt  \n",
            "  inflating: labels/validation/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.jpg  \n",
            " extracting: labels/validation/person_138_jpg.rf.6a31b4d275164ae2cf90bed6e0495201.txt  \n",
            "  inflating: labels/validation/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.jpg  \n",
            " extracting: labels/validation/person_139_jpg.rf.c20f5d62ff3518fa40d8608d110dfc76.txt  \n",
            "  inflating: labels/validation/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.jpg  \n",
            " extracting: labels/validation/person_143_jpg.rf.bbfcd9b09c660a2c33403083773d27ff.txt  \n",
            "  inflating: labels/validation/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.jpg  \n",
            " extracting: labels/validation/person_144_jpg.rf.6e96e3f80249b7c32e626364d99e7a6d.txt  \n",
            "  inflating: labels/validation/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.jpg  \n",
            " extracting: labels/validation/person_145_jpg.rf.01d2298f89b603e84a633eef8bc86f14.txt  \n",
            "  inflating: labels/validation/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.jpg  \n",
            " extracting: labels/validation/person_147_jpg.rf.d586255c4c849bdf965a7b136ebafa2f.txt  \n",
            "  inflating: labels/validation/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.jpg  \n",
            " extracting: labels/validation/person_148_jpg.rf.fb01a91c813c8763c51ade8466ae7fc1.txt  \n",
            "  inflating: labels/validation/person_149_jpg.rf.88955d0abb653e767920572661b3c985.jpg  \n",
            " extracting: labels/validation/person_149_jpg.rf.88955d0abb653e767920572661b3c985.txt  \n",
            "  inflating: labels/validation/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.jpg  \n",
            " extracting: labels/validation/person_14_jpg.rf.b68a28d4414f6bfe120c79223b26d1b9.txt  \n",
            "  inflating: labels/validation/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.jpg  \n",
            " extracting: labels/validation/person_150_jpg.rf.35673629cce934e42ab7b621768b7259.txt  \n",
            "  inflating: labels/validation/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.jpg  \n",
            " extracting: labels/validation/person_15_jpg.rf.3b688f3b7ad2794ca1f818b1670da05e.txt  \n",
            "  inflating: labels/validation/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.jpg  \n",
            " extracting: labels/validation/person_189_jpg.rf.0d2c844f516fbcbe0b76c9cf99b830ee.txt  \n",
            "  inflating: labels/validation/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.jpg  \n",
            "  inflating: labels/validation/person_47_jpg.rf.5a77f654a3834b43b59d7bea5144a4dd.txt  \n",
            "  inflating: labels/validation/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.jpg  \n",
            "  inflating: labels/validation/person_48_jpg.rf.304e4d45e70ba60c55d831cc49247126.txt  \n",
            "  inflating: labels/validation/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.jpg  \n",
            "  inflating: labels/validation/person_49_jpg.rf.1c325080e7333d67f641cfad0b1179db.txt  \n",
            "  inflating: labels/validation/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.jpg  \n",
            "  inflating: labels/validation/person_50_jpg.rf.44931cfad9349a739cb5a10ef8ded1f5.txt  \n",
            "  inflating: labels/validation/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.jpg  \n",
            "  inflating: labels/validation/person_51_jpg.rf.e99e751434ff42b8b2993425c1a4bbbd.txt  \n",
            "  inflating: labels/validation/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.jpg  \n",
            "  inflating: labels/validation/person_52_jpg.rf.dac0d6952bd02e4cf0e672b7ada28936.txt  \n",
            "  inflating: labels/validation/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.jpg  \n",
            "  inflating: labels/validation/person_53_jpg.rf.367aa651ac0e432c90ec30c152432123.txt  \n",
            "  inflating: labels/validation/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.jpg  \n",
            "  inflating: labels/validation/person_54_jpg.rf.0fa0bff2a0f51916b7ebf10eeecfce10.txt  \n",
            "  inflating: labels/validation/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.jpg  \n",
            "  inflating: labels/validation/person_55_jpg.rf.48118e1c00cad1a308fcf0325bf9ac4d.txt  \n",
            "  inflating: labels/validation/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.jpg  \n",
            " extracting: labels/validation/person_59_jpg.rf.bc5b22340b31f1ca44f9fc7519892f49.txt  \n",
            "  inflating: labels/validation/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.jpg  \n",
            "  inflating: labels/validation/person_63_jpg.rf.608f75906a862624852c4f0b9adab66f.txt  \n",
            "  inflating: labels/validation/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.jpg  \n",
            "  inflating: labels/validation/person_64_jpg.rf.eda1087c40af5cf4e0a33a80227341c4.txt  \n",
            "  inflating: labels/validation/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.jpg  \n",
            "  inflating: labels/validation/person_65_jpg.rf.e9b46af2793f3ef9c1d7d185cc3248bf.txt  \n",
            "  inflating: labels/validation/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.jpg  \n",
            "  inflating: labels/validation/person_66_jpg.rf.933f0fe0b51d4279200ed2a60d760ffa.txt  \n",
            "  inflating: labels/validation/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.jpg  \n",
            "  inflating: labels/validation/person_67_jpg.rf.a776791d7d5deeeceda276530c2eb978.txt  \n",
            "  inflating: labels/validation/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.jpg  \n",
            "  inflating: labels/validation/person_68_jpg.rf.e9986b7bac89352294dac56cadd6ebf8.txt  \n",
            "  inflating: labels/validation/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.jpg  \n",
            "  inflating: labels/validation/person_69_jpg.rf.49d4caa98778ce83ec36c7fa53421de8.txt  \n",
            "  inflating: labels/validation/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.jpg  \n",
            " extracting: labels/validation/person_6_jpg.rf.3267fe4a207f083dbce78e2d07f3c6ba.txt  \n",
            "  inflating: labels/validation/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.jpg  \n",
            "  inflating: labels/validation/person_70_jpg.rf.561514201e16d8d03866a0a17ef0e698.txt  \n",
            "  inflating: labels/validation/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.jpg  \n",
            "  inflating: labels/validation/person_71_jpg.rf.c019c28111de87622b3500be447dcaf7.txt  \n",
            "  inflating: labels/validation/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.jpg  \n",
            "  inflating: labels/validation/person_72_jpg.rf.008c0d28731230c09348b5f85572d926.txt  \n",
            "  inflating: labels/validation/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.jpg  \n",
            "  inflating: labels/validation/person_73_jpg.rf.4b1b628e6af177711a1631d05975fe10.txt  \n",
            "  inflating: labels/validation/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.jpg  \n",
            "  inflating: labels/validation/person_74_jpg.rf.5bb669490c27c0b8ad0c332e281163c3.txt  \n",
            "  inflating: labels/validation/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.jpg  \n",
            "  inflating: labels/validation/person_75_jpg.rf.2e2785f9f1e53650e1e44aa95a655013.txt  \n",
            "  inflating: labels/validation/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.jpg  \n",
            " extracting: labels/validation/person_82_jpg.rf.bb96706f7387991c11dadc8521316198.txt  \n",
            "  inflating: labels/validation/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.jpg  \n",
            "  inflating: labels/validation/person_84_jpg.rf.cd1991970755efcfbfd2729752dd7eaa.txt  \n",
            "  inflating: labels/validation/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.jpg  \n",
            "  inflating: labels/validation/person_85_jpg.rf.d2d0aac0e45acb1c12c19a88d8b3d1ea.txt  \n",
            "  inflating: labels/validation/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.jpg  \n",
            "  inflating: labels/validation/person_86_jpg.rf.73b3585b42440f05d21176e9b8317bab.txt  \n",
            "  inflating: labels/validation/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.jpg  \n",
            "  inflating: labels/validation/person_87_jpg.rf.76944ed3e9d5034c91bcdd6067de40ca.txt  \n",
            "  inflating: labels/validation/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.jpg  \n",
            "  inflating: labels/validation/person_88_jpg.rf.7c1294b4ef6d6bad2fa8f54aa4f0ed41.txt  \n",
            "  inflating: labels/validation/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.jpg  \n",
            "  inflating: labels/validation/person_89_jpg.rf.52102f665dce9f6eb4ed2b60bb5cabb0.txt  \n",
            "  inflating: labels/validation/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.jpg  \n",
            "  inflating: labels/validation/person_90_jpg.rf.746be1dffafa51b474cf1580c6787028.txt  \n",
            "  inflating: labels/validation/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.jpg  \n",
            "  inflating: labels/validation/person_91_jpg.rf.4c373671a35adf7ab55868967b2ff33d.txt  \n",
            "  inflating: labels/validation/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.jpg  \n",
            "  inflating: labels/validation/person_92_jpg.rf.d9fe2c9b3ef2ddce372b931eda185bd8.txt  \n",
            "  inflating: labels/validation/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.jpg  \n",
            "  inflating: labels/validation/person_93_jpg.rf.9c29b7bcbcc6687d2d6c488b05abfa06.txt  \n",
            "  inflating: labels/validation/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.jpg  \n",
            "  inflating: labels/validation/person_94_jpg.rf.a15963b923ab8220eabff7d2f2ba71e6.txt  \n",
            "  inflating: labels/validation/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.jpg  \n",
            "  inflating: labels/validation/person_95_jpg.rf.d477d63fd274c2f9839d5be9fa0beded.txt  \n",
            "  inflating: labels/validation/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.jpg  \n",
            "  inflating: labels/validation/person_96_jpg.rf.1582096ded2e494ac11e3491a1ad0529.txt  \n",
            "  inflating: labels/validation/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.jpg  \n",
            "  inflating: labels/validation/person_97_jpg.rf.9eea6b4a5177c90464ceafacea5be04b.txt  \n",
            "  inflating: labels/validation/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.jpg  \n",
            "  inflating: labels/validation/person_98_jpg.rf.73e5d4751a4f80b73042fa5ba0493854.txt  \n",
            "  inflating: labels/validation/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.jpg  \n",
            "  inflating: labels/validation/person_99_jpg.rf.faf3536524362d058e96a3e74e8e3dbd.txt  \n"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!unzip /content/gdrive/MyDrive/freedomtech.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "5ff03dce-8c08-45e1-92da-e4cb9f5ca9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=/content/datasets/data.yaml, epochs=100, patience=50, batch=16, imgsz=800, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train4\n",
            "2023-12-21 14:55:25.085708: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-21 14:55:25.085772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-21 14:55:25.087615: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-21 14:55:26.188581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.Detect                [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/labels/training... 73 images, 26 backgrounds, 0 corrupt: 100% 73/73 [00:00<00:00, 1783.28it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/labels/training.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/labels/validation... 73 images, 26 backgrounds, 0 corrupt: 100% 73/73 [00:00<00:00, 2776.98it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/labels/validation.cache\n",
            "Image sizes 800 train, 800 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      6.37G       3.79      39.99      3.235          8        800: 100% 5/5 [00:09<00:00,  1.86s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.15s/it]\n",
            "                   all         73         47          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      7.61G      3.535       39.9      2.981          7        800: 100% 5/5 [00:04<00:00,  1.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      7.63G      3.322      16.44      2.888          9        800: 100% 5/5 [00:07<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47   0.000274      0.128    0.00019   4.52e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      7.63G       2.56      5.208      2.216          8        800: 100% 5/5 [00:04<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.71it/s]\n",
            "                   all         73         47      0.219     0.0638     0.0576     0.0175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      7.64G      2.155      3.534      1.998         12        800: 100% 5/5 [00:06<00:00,  1.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.265      0.468      0.235     0.0934\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      7.64G      1.975      2.298      1.791         12        800: 100% 5/5 [00:04<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.59it/s]\n",
            "                   all         73         47       0.53      0.234      0.408      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      7.64G      1.939      1.951      1.704          8        800: 100% 5/5 [00:05<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         73         47      0.646      0.468      0.488      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      7.64G      1.689      1.963      1.682          9        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.31it/s]\n",
            "                   all         73         47      0.776      0.665      0.784      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      7.64G      1.602      1.485      1.499          6        800: 100% 5/5 [00:05<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.88it/s]\n",
            "                   all         73         47      0.919      0.383      0.898      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      7.64G      1.645      1.667      1.594          6        800: 100% 5/5 [00:05<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                   all         73         47      0.935      0.921      0.948       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      7.64G      1.531       1.45      1.623          3        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.80it/s]\n",
            "                   all         73         47      0.934      0.606      0.901      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      7.64G      1.519      1.396      1.594         11        800: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
            "                   all         73         47      0.922      0.872      0.919      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      7.64G      1.566      1.159      1.573          6        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.937      0.957      0.968      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      7.64G      1.448      1.277      1.392         10        800: 100% 5/5 [00:06<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
            "                   all         73         47       0.91      0.957       0.96      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      7.64G      1.285       1.44      1.368         12        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.956      0.923      0.969      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      7.64G      1.412      1.026      1.419          7        800: 100% 5/5 [00:06<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.43it/s]\n",
            "                   all         73         47      0.897      0.936      0.947      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      7.64G      1.393       1.25      1.345          9        800: 100% 5/5 [00:04<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.90it/s]\n",
            "                   all         73         47      0.892      0.352      0.575      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      7.64G      1.397      1.481      1.412          9        800: 100% 5/5 [00:06<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.46it/s]\n",
            "                   all         73         47      0.785      0.638      0.756      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      7.64G      1.513      1.367      1.515         10        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         73         47      0.828      0.511      0.705      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      7.64G      1.316      1.186      1.478          5        800: 100% 5/5 [00:06<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.55it/s]\n",
            "                   all         73         47      0.834      0.915      0.919      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100      7.64G      1.445      1.355      1.371          7        800: 100% 5/5 [00:04<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.78it/s]\n",
            "                   all         73         47       0.84      0.617      0.833      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100      7.64G      1.437      1.561      1.478          5        800: 100% 5/5 [00:06<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                   all         73         47      0.927      0.814      0.902      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100      7.64G      1.543      1.214      1.497          7        800: 100% 5/5 [00:05<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                   all         73         47      0.749      0.766      0.792      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100      7.64G      1.637      2.783      1.763         11        800: 100% 5/5 [00:08<00:00,  1.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.81it/s]\n",
            "                   all         73         47      0.731      0.811      0.805      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100      7.64G      1.595      1.831      1.525         10        800: 100% 5/5 [00:04<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                   all         73         47      0.696      0.809      0.793      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100      7.64G      1.451      1.951      1.408          7        800: 100% 5/5 [00:06<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.876      0.872      0.898      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100      7.64G      1.423     0.9924       1.48          6        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.61it/s]\n",
            "                   all         73         47      0.894      0.894      0.919      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100      7.64G      1.393     0.8877      1.484          6        800: 100% 5/5 [00:06<00:00,  1.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.74it/s]\n",
            "                   all         73         47      0.944      0.872      0.933       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100      7.64G      1.485      1.265      1.457          6        800: 100% 5/5 [00:05<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.29it/s]\n",
            "                   all         73         47      0.932       0.87      0.945      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100      7.64G      1.326       1.15      1.322         10        800: 100% 5/5 [00:05<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.76it/s]\n",
            "                   all         73         47      0.863      0.915      0.951      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100      7.64G      1.285     0.9833       1.35          4        800: 100% 5/5 [00:05<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                   all         73         47      0.937      0.951      0.952      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100      7.64G      1.444     0.8683      1.383          9        800: 100% 5/5 [00:04<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.846      0.745      0.784      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100      7.64G      1.409      0.912      1.395          9        800: 100% 5/5 [00:06<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                   all         73         47      0.855      0.979      0.961      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100      7.64G      1.371     0.8896      1.419          8        800: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.893      0.957      0.969      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100      7.64G      1.318     0.8576      1.335          7        800: 100% 5/5 [00:07<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.855      0.979      0.968      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100      7.64G      1.537     0.9146      1.515          8        800: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                   all         73         47      0.933      0.979       0.98      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100      7.64G      1.386     0.8099      1.297          9        800: 100% 5/5 [00:07<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.899       0.95      0.973      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100      7.64G      1.466      0.817      1.498          7        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.916      0.979      0.985      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100      7.64G      1.277     0.7098      1.296          6        800: 100% 5/5 [00:06<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.88it/s]\n",
            "                   all         73         47      0.915      0.917      0.974      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100      7.64G      1.348      0.785      1.358          9        800: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.66it/s]\n",
            "                   all         73         47      0.912      0.957      0.983      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100      7.64G      1.414     0.8029       1.38          9        800: 100% 5/5 [00:05<00:00,  1.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.915      0.979      0.985      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100      7.64G      1.471     0.7584       1.46          9        800: 100% 5/5 [00:05<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                   all         73         47       0.95      0.979      0.986      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100      7.64G      1.298     0.7388      1.402          6        800: 100% 5/5 [00:05<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.931      0.979      0.984      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100      7.64G      1.459      0.765      1.537          6        800: 100% 5/5 [00:05<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         73         47      0.916      0.979       0.98      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100      7.64G      1.226     0.7911      1.321          6        800: 100% 5/5 [00:05<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.81it/s]\n",
            "                   all         73         47      0.934      0.979       0.98      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100      7.64G      1.243     0.7737      1.296         10        800: 100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.39it/s]\n",
            "                   all         73         47      0.954      0.979      0.984      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100      7.64G      1.194     0.7483      1.336          7        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.955      0.979      0.976      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100      7.64G       1.21     0.7204      1.232          6        800: 100% 5/5 [00:06<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.52it/s]\n",
            "                   all         73         47      0.939      0.991      0.986      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100      7.64G      1.203     0.7292      1.289          7        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.978      0.933       0.98      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100      7.64G      1.276     0.6809      1.281          7        800: 100% 5/5 [00:06<00:00,  1.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.56it/s]\n",
            "                   all         73         47      0.973      0.936      0.982      0.649\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100      7.64G      1.353     0.7707      1.432          7        800: 100% 5/5 [00:05<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.939      0.974      0.983      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     52/100      7.64G      1.269     0.7996      1.351          7        800: 100% 5/5 [00:06<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.80it/s]\n",
            "                   all         73         47      0.955      0.906      0.958      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     53/100      7.64G      1.219     0.7022      1.282          6        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.936      0.939      0.973      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     54/100      7.64G      1.162     0.6744      1.224          9        800: 100% 5/5 [00:07<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.946      0.979      0.981      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     55/100      7.64G      1.282     0.6695      1.354          8        800: 100% 5/5 [00:05<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.954      0.957      0.984      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     56/100      7.64G       1.26     0.6817      1.349          6        800: 100% 5/5 [00:07<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.80it/s]\n",
            "                   all         73         47        0.9      0.955      0.982       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     57/100      7.64G      1.357     0.7183       1.33          9        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.78it/s]\n",
            "                   all         73         47      0.914      0.979      0.973      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     58/100      7.64G      1.272     0.7188      1.351          6        800: 100% 5/5 [00:06<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
            "                   all         73         47      0.903      0.994      0.981      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     59/100      7.64G      1.195     0.7148      1.246         10        800: 100% 5/5 [00:04<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.59it/s]\n",
            "                   all         73         47      0.888          1      0.988      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     60/100      7.64G      1.075     0.6271      1.236          7        800: 100% 5/5 [00:06<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
            "                   all         73         47      0.919      0.967      0.983      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     61/100      7.64G       1.12     0.6227      1.199          9        800: 100% 5/5 [00:05<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                   all         73         47      0.957      0.957      0.983      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100      7.64G      1.152     0.5812      1.228          3        800: 100% 5/5 [00:05<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.952      0.979      0.983      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100      7.64G      1.157     0.7076      1.293          6        800: 100% 5/5 [00:04<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                   all         73         47      0.956      0.979      0.983      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100      7.64G      1.113     0.6602      1.203          5        800: 100% 5/5 [00:05<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.82it/s]\n",
            "                   all         73         47      0.959      0.996      0.976      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100      7.64G      1.164     0.6478      1.238          7        800: 100% 5/5 [00:05<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.30it/s]\n",
            "                   all         73         47      0.958          1      0.976      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100      7.64G      1.167     0.6193      1.246          9        800: 100% 5/5 [00:05<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.958          1      0.974      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100      7.64G      1.206     0.6236      1.266         10        800: 100% 5/5 [00:05<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                   all         73         47      0.957          1      0.978      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100      7.64G      1.189     0.6683      1.233          8        800: 100% 5/5 [00:04<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.957          1      0.988       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100      7.64G      1.187      0.639      1.241          9        800: 100% 5/5 [00:07<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.71it/s]\n",
            "                   all         73         47      0.957          1      0.992      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      7.64G      1.125     0.6195      1.221          5        800: 100% 5/5 [00:05<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47       0.94      0.996      0.991      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100      7.64G      1.157     0.5952      1.259         10        800: 100% 5/5 [00:07<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.955      0.979      0.986      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      7.64G      1.156     0.6346      1.231          8        800: 100% 5/5 [00:05<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.78it/s]\n",
            "                   all         73         47      0.939      0.975      0.956      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100      7.64G      1.066     0.5662      1.154          8        800: 100% 5/5 [00:06<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
            "                   all         73         47      0.958      0.978      0.984      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      7.64G      1.118     0.6182      1.214          6        800: 100% 5/5 [00:05<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.30it/s]\n",
            "                   all         73         47       0.94      0.996      0.992      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100      7.64G      1.077     0.5702      1.222          8        800: 100% 5/5 [00:05<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.966      0.979      0.993      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100      7.64G      1.077     0.5838      1.205          9        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                   all         73         47      0.987      0.979      0.995      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100      7.64G      1.024      0.583      1.197          5        800: 100% 5/5 [00:05<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         73         47      0.979          1      0.995      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100      7.64G      1.065     0.5584      1.184          9        800: 100% 5/5 [00:05<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                   all         73         47      0.979      0.996      0.995      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      7.64G     0.9717     0.5383      1.109          9        800: 100% 5/5 [00:04<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
            "                   all         73         47      0.979      0.996      0.995      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      7.64G      1.015      0.557      1.156         10        800: 100% 5/5 [00:06<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                   all         73         47      0.979      0.996      0.995      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100      7.64G     0.9954     0.5835      1.266         11        800: 100% 5/5 [00:04<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.979      0.998      0.995      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      7.64G     0.9536     0.5376      1.204          9        800: 100% 5/5 [00:06<00:00,  1.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.48it/s]\n",
            "                   all         73         47      0.979      0.998      0.995      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100      7.64G      1.116     0.6433      1.285          8        800: 100% 5/5 [00:05<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.979      0.995      0.995       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100      7.64G     0.9776     0.5571      1.196          7        800: 100% 5/5 [00:07<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
            "                   all         73         47      0.979      0.999      0.995      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100      7.64G       1.28     0.6406      1.189          1        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.979      0.999      0.995      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100      7.64G      1.107     0.6028      1.254          5        800: 100% 5/5 [00:07<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         73         47      0.979          1      0.995      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100      7.64G     0.9486     0.5547      1.144          5        800: 100% 5/5 [00:05<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.74it/s]\n",
            "                   all         73         47      0.979          1      0.995      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100      7.64G     0.9265     0.5102      1.031          5        800: 100% 5/5 [00:06<00:00,  1.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.977          1      0.995      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100      7.64G      1.025     0.5656      1.163          9        800: 100% 5/5 [00:04<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                   all         73         47      0.977          1      0.995        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100      7.64G     0.9561     0.5096      1.184          5        800: 100% 5/5 [00:05<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.90it/s]\n",
            "                   all         73         47      0.977          1      0.995      0.779\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     91/100      7.64G     0.8824     0.5342      1.207          2        800: 100% 5/5 [00:05<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.05s/it]\n",
            "                   all         73         47      0.977          1      0.995      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     92/100      7.64G      1.003       0.54      1.218          5        800: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.90it/s]\n",
            "                   all         73         47      0.975          1      0.995      0.786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     93/100      7.64G     0.9927     0.5384      1.215          6        800: 100% 5/5 [00:03<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n",
            "                   all         73         47      0.974          1      0.995      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     94/100      7.64G     0.9051     0.4741      1.167          6        800: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.48it/s]\n",
            "                   all         73         47      0.975          1      0.995      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     95/100      7.64G     0.9013     0.5074      1.192          4        800: 100% 5/5 [00:03<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
            "                   all         73         47      0.975          1      0.995      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     96/100      7.64G     0.9473     0.5176      1.188          5        800: 100% 5/5 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.29it/s]\n",
            "                   all         73         47      0.976          1      0.995      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     97/100      7.64G     0.9199     0.4865      1.244          7        800: 100% 5/5 [00:03<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         73         47      0.976          1      0.995      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     98/100      7.64G     0.8773      0.476      1.174          5        800: 100% 5/5 [00:03<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.85it/s]\n",
            "                   all         73         47      0.976          1      0.995      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     99/100      7.64G     0.9293     0.4714      1.116          6        800: 100% 5/5 [00:04<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.44it/s]\n",
            "                   all         73         47      0.976          1      0.995      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "    100/100      7.64G     0.8713     0.4795      1.213          7        800: 100% 5/5 [00:03<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.21it/s]\n",
            "                   all         73         47      0.975          1      0.995      0.795\n",
            "\n",
            "100 epochs completed in 0.230 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.25it/s]\n",
            "                   all         73         47      0.977          1      0.995      0.808\n",
            "Speed: 0.3ms pre-process, 7.1ms inference, 0.0ms loss, 2.2ms post-process per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train model=yolov8s.pt data=/content/datasets/data.yaml epochs=100 imgsz=800 plots=True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}